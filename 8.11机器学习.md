[TOC]
# 优化方法总结
## 梯度下降法
已在**梯度下降优化方法总结**做了更详细的介绍
## 牛顿法
牛顿法是一种在**实数域和复数域**上近似求解方程的方法。方法使用函数f (x)的泰勒级数的前面几项来寻找方程f (x) = 0的根。牛顿法最大的特点就在于它的收敛速度很快。
### 步骤
选择一个接近函数 f (x)零点的 x0，计算相应的 f (x0) 和切线斜率f  ' (x0)（这里f ' 表示函数 f  的导数）。然后我们计算穿过点(x0,  f  (x0)) 并且斜率为f '(x0)的直线和 x 轴的交点的x坐标，也就是求如下方程的解：
```math
xf^{'}(x_0)+f(x_0)-x_0f^{'}(x_0)=0
```
我们将新求得的点的 x 坐标命名为x1，通常x1会比x0更接近方程f  (x) = 0的解。因此我们现在可以利用x1开始下一轮迭代。迭代公式可化简为如下所示：
```math
x_{n+1}=x_n-\frac{f(x_n)}{f^{'}(x_n)}
```
已经证明，如果f  '(x) 是连续的，并且待求的零点x是孤立的，那么在零点x周围存在一个区域，只要初始值x0位于这个邻近区域内，那么牛顿法必定收敛。 并且，如果f  ' (x)不为0, 那么牛顿法将具有平方收敛的性能. 粗略的说，这意味着每迭代一次，牛顿法结果的有效数字将增加一倍。下图为一个牛顿法执行过程的例子。

　　由于牛顿法是基于当前位置的切线来确定下一次的位置，所以牛顿法又被很形象地称为是"切线法"。牛顿法的搜索路径（二维情况）如下图所示：
![image](https://images2017.cnblogs.com/blog/1022856/201709/1022856-20170916202719078-1588446775.gif)
### 与梯度下降法效率对比
从本质上去看，**牛顿法是二阶收敛，梯度下降是一阶收敛**，所以牛顿法就更快。如果更通俗地说的话，比如你想找一条最短的路径走到一个盆地的最底部，梯度下降法每次只从你当前所处位置选一个坡度最大的方向走一步，牛顿法在选择方向时，**不仅会考虑坡度是否够大，还会考虑你走了一步之后，坡度是否会变得更大**。所以，可以说牛顿法比梯度下降法*看得更远一点*，能更快地走到最底部。（牛顿法目光更加长远，所以少走弯路；相对而言，梯度下降法只考虑了局部的最优，没有全局思想。）

　　根据wiki上的解释，从几何上说，牛顿法就是用一个二次曲面去拟合你当前所处位置的局部曲面，而梯度下降法是用一个平面去拟合当前的局部曲面，通常情况下，二次曲面的拟合会比平面更好，所以牛顿法选择的下降路径会更符合真实的最优下降路径。

　　![image](https://images2017.cnblogs.com/blog/1022856/201709/1022856-20170916202746985-1087770168.png)
> 红色的牛顿法的迭代路径，绿色的是梯度下降法的迭代路径。

### 优缺点
- 优点：二阶收敛，收敛速度快；
- 缺点：牛顿法是一种迭代算法，每一步都需要求解目标函数的Hessian矩阵的逆矩阵，计算比较复杂。
## 拟牛顿法(BFGS)
**拟牛顿法的本质思想是改善牛顿法每次需要求解复杂的Hessian矩阵的逆矩阵的缺陷**，它使用正定矩阵来**近似Hessian矩阵的逆**，从而简化了运算的复杂度。拟牛顿法和最速下降法一样只要求每一步迭代时知道目标函数的梯度。通过测量梯度的变化，构造一个目标函数的模型使之足以产生超线性收敛性。这类方法大大优于最速下降法，尤其对于困难的问题。另外，因为拟牛顿法不需要二阶导数的信息，所以有时比牛顿法更为有效。如今，优化软件中包含了大量的拟牛顿算法用来解决无约束，约束，和大规模的优化问题。
### 步骤
首先构造目标函数在当前迭代xk的二次模型：
![image](https://images0.cnblogs.com/blog2015/764050/201508/222253268161863.png)

这里Bk是一个对称正定矩阵，于是我们取这个二次模型的最优解作为搜索方向，并且得到新的迭代点

![image](https://images0.cnblogs.com/blog2015/764050/201508/222254384106201.png)

其中我们要求步长ak 满足Wolfe条件。这样的迭代与牛顿法类似，区别就在于用近似的Hesse矩阵Bk  代替真实的Hesse矩阵。所以拟牛顿法最关键的地方就是每一步迭代中矩阵Bk 的更新。现在假设得到一个新的迭代xk+1，并得到一个新的二次模型

![image](https://images0.cnblogs.com/blog2015/764050/201508/222256385508904.png)

我们尽可能地利用上一步的信息来选取Bk。具体地，我们要求

![image](https://images0.cnblogs.com/blog2015/764050/201508/222257530664204.png)

从而得到

![image](https://images0.cnblogs.com/blog2015/764050/201508/222258392223638.png)

## L-BFGS

## 共轭梯度法