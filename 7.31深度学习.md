# 深度学习
[TOC]
## 梯度不稳定问题
由于在进行参数更新时，涉及到后面激活函数的导数的累积，故激活函数的导数曲线将直接影响前面参数更新的速度。
### 梯度爆炸
sigmoid函数导数图像在0处取得导数最大值1/4，当abs(w)>4时我们可能得到wjf’(zj)>1的结果，经过多层累乘，梯度会迅速增长，造成梯度爆炸。由此计算出a的数值变化范围很小，仅仅在此窄范围内会出现梯度爆炸问题。而最普遍发生的是梯度消失问题。 
### 梯度消失
sigmoid函数导数图像在0处取得导数最大值1/4，当使用一个均值0标准差为1的高斯分布来初始化权值，所有的权重通常会满足 |w|<1。有了这些信息，我们发现会有wjf’(zj)<1/4。并且在我们进行了所有这些项的乘积时，最终结果肯定会指数级下降：项越多，乘积下降的越快。 这就是梯度消失出现的原因。 
### 解决方法
#### 1.ReLu函数(等非饱和激活函数)代替Sigmoid
1. sigmoid函数值在[0,1],ReLU函数值在[0,+无穷]，所以sigmoid函数可以描述概率，ReLU适合用来描述实数
2. sigmoid函数的梯度随着x的增大或减小消失，而ReLU不会。 
ReLU的导数为1，所以f’(zj) = 1。
3. 收敛超快

但弊端也有，神经元会很脆弱，因为当出现小于零的数时该神经元将会“死亡”。若学习率不恰当将导致神经元大量死亡。   

利用其它非饱和激活函数可以缓解神经元死亡问题。   
**ELUs(指数线性单元)**   
ELUs是“指数线性单元”，它试图将激活函数的平均值接近零，从而加快学习的速度。同时，它还能通过正值的标识来避免梯度消失的问题。根据一些研究，ELUs分类精确度是高于ReLUs的。下面是关于ELU细节信息的详细介绍：![image](http://p0.ifengimg.com/pmop/2017/0701/A9B535C61C2D63E152DE2CEECB4531EE83E80208_size26_w740_h230.jpeg)
**Leaky ReLU**   
ReLU是将所有的负值都设为零，相反，Leaky ReLU是给所有负值赋予一个非零斜率。Leaky ReLU激活函数是在声学模型（2013）中首次提出的。以数学的方式我们可以表示为：   

![image](http://p0.ifengimg.com/pmop/2017/0701/CFC5A1C95A84A6D8CF3FFC1DD30597782AEEAE57_size20_w740_h231.jpeg)
ai是（1，+∞）区间内的固定参数。   
**参数化修正线性单元（PReLU）**    
PReLU可以看作是Leaky ReLU的一个变体。在PReLU中，负值部分的斜率是根据数据来定的，而非预先定义的。在ImageNet分类（2015，Russakovsky等）上，PReLU是超越人类分类水平的关键所在。   
**随机纠正线性单元（RReLU）**   
“随机纠正线性单元”RReLU也是Leaky ReLU的一个变体。在RReLU中，负值的斜率在训练中是随机的，在之后的测试中就变成了固定的了。RReLU的亮点在于，在训练环节中，aji是从一个均匀的分布U(I,u)中随机抽取的数值。形式上来说，我们能得到以下结果：![image](http://p0.ifengimg.com/pmop/2017/0701/B3F2F3EA627EBB55D88C8F8FB36942C56B350A4B_size14_w740_h221.jpeg)
#### 2.BN(批归一化层)填充
1. 加速收敛
2. 控制过拟合，可以少用或不用Dropout和正则
3. 降低网络对初始化权重不敏感
4. 允许使用较大的学习率 

在每一层输入的时候，加个BN预处理操作。BN应作用在非线性映射前，即对x=Wu+b做规范化。在BN中，是通过将activation规范为均值和方差一致的手段使得原本会减小的activation的scale变大。可以说是一种更有效的local response normalization方法.
#### 3.LSTM(长短期记忆)
## 局部响应归一化和BN批归一化
### LRN局部响应归一化(Local Response Normalization）
主要是模拟生物中神经元的*侧抑制*。
pass
### BN批归一化
在单位高斯内都获得激活的一种手段。
#### 为何添加BN层
神经网络学习过程本质就是为了学习数据分布，一旦训练数据与测试数据的分布不同，那么网络的泛化能力也大大降低；另外一方面，一旦每批训练数据的分布各不相同(batch 梯度下降)，那么网络就要在每次迭代都去学习适应不同的分布，这样将会大大降低网络的训练速度，这也正是为什么我们需要对数据都要做一个归一化预处理的原因。

对于深度网络的训练是一个复杂的过程，只要网络的前面几层发生微小的改变，那么后面几层就会被累积放大下去。一旦网络某一层的输入数据的分布发生改变，那么这一层网络就需要去适应学习这个新的数据分布，所以如果训练过程中，训练数据的分布一直在发生变化，那么将会影响网络的训练速度。

我们知道网络一旦train起来，那么参数就要发生更新，除了输入层的数据外(因为输入层数据，我们已经人为的为每个样本归一化)，后面网络每一层的输入数据分布是一直在发生变化的，因为在训练的时候，前面层训练参数的更新将导致后面层输入数据分布的变化。以网络第二层为例：网络的第二层输入，是由第一层的参数和input计算得到的，而第一层的参数在整个训练过程中一直在变化，因此必然会引起后面每一层输入数据分布的改变。我们把网络中间层在训练过程中，数据分布的改变称之为：“Internal  Covariate Shift”。Paper所提出的算法，就是要解决在训练过程中，中间层数据分布发生改变的情况，于是就有了Batch  Normalization，这个牛逼算法的诞生。
#### 好处
BN算法（Batch Normalization）其强大之处如下：
(1)你可以选择比较大的初始学习率，让你的训练速度飙涨。以前还需要慢慢调整学习率，甚至在网络训练到一半的时候，还需要想着学习率进一步调小的比例选择多少比较合适，现在我们可以采用初始很大的学习率，然后学习率的衰减速度也很大，因为这个算法收敛很快。当然这个算法即使你选择了较小的学习率，也比以前的收敛速度快，因为它具有快速训练收敛的特性；

(2)你再也不用去理会过拟合中drop out、L2正则项参数的选择问题，采用BN算法后，你可以移除这两项了参数，或者可以选择更小的L2正则约束参数了，因为BN具有提高网络泛化能力的特性；

(3)再也不需要使用使用局部响应归一化层了（局部响应归一化是Alexnet网络用到的方法，搞视觉的估计比较熟悉），因为BN本身就是一个归一化网络层；

(4)可以把训练数据彻底打乱
#### 实现
先预处理
```math
\hat{x}^{(k)} = \frac{\hat{x}^{(k)}-E[\hat{x}^{(k)}]}{\sqrt{Var[\hat{x}^{(k)}]}}
```
上面的E(xk)指的是每一批训练数据神经元xk的平均值；然后分母就是每一批数据神经元xk激活度的一个标准差了。   
如果是仅仅使用上面的归一化公式，对网络某一层A的输出数据做归一化，然后送入网络下一层B，这样是会影响到本层网络A所学习到的特征的。打个比方，比如我网络中间某一层学习到特征数据本身就分布在S型激活函数的两侧，你强制把它给我归一化处理、标准差也限制在了1，把数据变换成分布于s函数的中间部分，这样就相当于我这一层网络**所学习到的特征分布被搞坏**了.   
所以这里必须进行**变换重构**，将学习分布恢复。引入了**可学习参数γ、β**，这就是算法关键之处：
```math
y^{(k)} = \gamma^{(k)}\hat{x}^{(k)}+\beta^{(k)}
```
每一个神经元xk都会有一对这样的参数γ、β。这样其实当：
```math
\gamma^{(k)}=\sqrt{Var[\hat{x}^{(k)}]}
```
```math
\beta^{(k)}=E[\hat{x}^{(k)}]
```
是可以恢复出原始的某一层所学到的特征的。因此我们引入了这个可学习重构参数γ、β，让我们的网络可以学习恢复出原始网络所要学习的特征分布
#### Batch Normalization在CNN中的使用
通过上面的学习，我们知道BN层是对于每个神经元做归一化处理，甚至只需要对某一个神经元进行归一化，而不是对一整层网络的神经元进行归一化。既然BN是对单个神经元的运算，那么在CNN中卷积层上要怎么搞？假如某一层卷积层有6个特征图，每个特征图的大小是100*100，这样就相当于这一层网络有6*100*100个神经元，如果采用BN，就会有6*100*100个参数γ、β，这样岂不是太恐怖了。因此卷积层上的BN使用，其实也是使用了类似权值共享的策略，把一整张特征图当做一个神经元进行处理。


卷积神经网络经过卷积后得到的是一系列的特征图，如果min-batch sizes为m，那么网络某一层输入数据可以表示为四维矩阵(m,f,p,q)，m为min-batch sizes，f为特征图个数，p、q分别为特征图的宽高。在cnn中我们可以把每个特征图看成是一个特征处理（一个神经元），因此在使用Batch Normalization，mini-batch size 的大小就是：m*p*q，于是对于每个特征图都只有一对可学习参数：γ、β。说白了吧，这就是相当于求取所有样本所对应的一个特征图的所有神经元的平均值、方差，然后对这个特征图神经元做归一化。
#### 在TensorFlow中
BN在TensorFlow中主要有两个函数:**tf.nn.moments**以及**tf.nn.batch_normalization**,两者需要配合使用,前者用来返回均值和方差,后者用来进行批处理(BN)
##### tf.nn.moments
参数解释：

- x 可以理解为我们输出的数据，形如 [batchsize, height, width, kernels]
- axes 表示在哪个维度上求解，是个list，例如 [0, 1, 2]
- name 就是个名字
- keep_dims 是否保持维度

这个函数的输出就是BN需要的mean和variance。
##### tf.nn.batch_normalization
参数解释：
- x同moments方法
- mean moments方法的输出之一
- variance moments方法的输出之一
- offset BN需要学习的参数
- scale BN需要学习的参数
- variance_epsilon 归一化时防止分母为0加的一个常量(平滑项)
##### 训练
训练的时候需要注意两点，(1)输入参数training=True,(2)计算loss时，要添加以下代码（即添加update_ops到最后的train_op中）。这样才能计算μ和σ的滑动平均（测试时会用到）
```
update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
  with tf.control_dependencies(update_ops):
    train_op = optimizer.minimize(loss)
 
```
